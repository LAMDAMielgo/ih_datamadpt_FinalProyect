{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATA FROM CATASTRO INSPIRE\n",
    "___________________________________________________________________________________________________\n",
    "\n",
    "Obteined through qGIS after mingling from a while with:\n",
    "- WMS service: http://ovc.catastro.meh.es/cartografia/INSPIRE/spadgcwms.aspx\n",
    "- WFS buildings : http://ovc.catastro.meh.es/INSPIRE/wfsBU.aspx?\n",
    "- todos los serivicios INSPIRE: http://www.catastro.minhap.es/webinspire/index.html\n",
    "\n",
    "*Notas: el uso de los canales WMS/WFS devuelven las capas antes de unificar con el programa Europeo Inspire, por lo que quizá sea la razón por la que no funcionan bien.\n",
    "\n",
    "Existen varios GitHubs enfocados a consultas del catastro con python:\n",
    "- **[pyCatastro](#https://github.com/gisce/pycatastro)**: permite realizar consultas en formato API. \n",
    ">>- No permite la descarga total de datos en función de municipio y provincia\n",
    ">>- Devuelve diccionarios\n",
    ">>- Para descargarme Madrid, debería obtener (1) Todas las vías, (2) Todas las siglas e iterar, haciendo mogollón de llamadas (not a good idea)\n",
    "\n",
    "- **[catastro-lib-python](#https://github.com/sperea/catastro-lib-python)**: parece un antecersor del anterior. No se ha probado pues se dejó de actualizar en 2018\n",
    "- **[Catastro Inspire Downloader](#https://github.com/geomatico/cidownloader)**: realizados por los mismos cartógrafos y desarrolladores que el complemento de qGIS, permite descargar datos en formato .geopackage\n",
    ">>- Permite descargar según provincia, municipio y proyección\n",
    ">>- Es poco consistente: al descargar Madrid a veces devuelve sólo datos de CadastralParcel o de BuildingParts. Comparando con los gmls incluidos en ZIPs que se pueden descargar a parte, los datos son incompletos. Posiblemente se un problema con la librería GDAL.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from itertools import combinations\n",
    "from itertools import chain\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import geopandas as gpd\n",
    "import geojson\n",
    "\n",
    "pd.set_option('display.max_rows', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RENAMING_OF_COLS = {'gml_id': 'ID',\n",
    "                    'localId_part': 'ID_part',\n",
    "                    'localId_PI': 'ID_pool',\n",
    "                    'numberOfFloorsAboveGround': 'nFloors_AG',\n",
    "                    'numberOfFloorsBelowGround': 'nFloors_BG',\n",
    "                    'heightAboveGround': 'height_AG',\n",
    "                    'heightBelowGround': 'height_BG',\n",
    "                    'areaValue': 'area_m2p',\n",
    "                    'value': 'area_m2c'}\n",
    "\n",
    "GEOMETRY_COLS = ['geometry', 'pos']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FUNCTIONAL PIPELINE PROTOTYPING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------ checking which columns should be purged\n",
    "\n",
    "def str_forUniques(num):\n",
    "    \"\"\"\n",
    "    Return different string depending of unique_len in checking_forUniques\n",
    "    \"\"\"\n",
    "    if num == 0: return 'ALL NULLS'\n",
    "    else: return 'Unique items'\n",
    "\n",
    "def checking_forUniques(gdf):\n",
    "    \"\"\"\n",
    "    input:\n",
    "    output:\n",
    "    \"\"\"\n",
    "    cols_with_one_element = []\n",
    "    \n",
    "    print(f\"\\n-------------------- Current Layers in {gdf.name} ------------------------\")\n",
    "    print(f\"------------------------------------------------------------------------\")\n",
    "    \n",
    "    for i,col in enumerate(gdf.columns.tolist()):\n",
    "        if (col not in GEOMETRY_COLS):\n",
    "            unique_len = len(gdf[str(col)].value_counts().tolist())\n",
    "            \n",
    "            if unique_len == 0: \n",
    "                print(f\"{i+1}. {col}:\\t\\t\\t{unique_len}\\t{str_forUniques(unique_len)}\")                \n",
    "            elif len(col) <= 12 and unique_len != 0: \n",
    "                print(f\"{i+1}. {col}:\\t\\t\\t\\t\\t{unique_len}\\t{str_forUniques(unique_len)}\")\n",
    "            elif 12 < len(col) <= 19 and unique_len != 0: \n",
    "                print(f\"{i+1}. {col}:\\t\\t\\t\\t{unique_len}\\t{str_forUniques(unique_len)}\")\n",
    "            elif 19 < len(col) <= 28 and unique_len != 0: \n",
    "                print(f\"{i+1}. {col}:\\t\\t\\t{unique_len}\\t{str_forUniques(unique_len)}\")\n",
    "            elif 28 < len(col) <= 36 and unique_len != 0: \n",
    "                print(f\"{i+1}. {col}:\\t\\t{unique_len}\\t{str_forUniques(unique_len)}\")\n",
    "            elif 36 < len(col) and unique_len != 0: \n",
    "                print(f\"{i+1}. {col}:\\t{unique_len}\\t{str_forUniques(unique_len)}\")\n",
    "            else: pass\n",
    "            \n",
    "            if (unique_len == 1) or (unique_len == 0): cols_with_one_element.append(col)\n",
    "            else: pass            \n",
    "        else: pass\n",
    "    \n",
    "    print(f\"------------------------------------------------------------------------\\n\")\n",
    "    return cols_with_one_element\n",
    "\n",
    "def droping_DupCols(gdf, drop_cols = True):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"   \n",
    "    if drop_cols:\n",
    "        cols_to_drop = checking_forUniques(gdf)\n",
    "        \n",
    "        print(f\"-------------- Droping DUPLICATED COLUMNS in {gdf.name} ------------------\")\n",
    "        [print(f'{i+1}. {col}\\v') for i, col in enumerate(cols_to_drop)] # repr without new line\n",
    "        \n",
    "        gdf.drop(cols_to_drop, \n",
    "                 axis=1, inplace = True)\n",
    "        \n",
    "        print(f\"-- Finished task -----------------------------------------------------\\n\")\n",
    "    else: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------ separate ID_parts if needed\n",
    "\n",
    "def get_part(x):\n",
    "    \"\"\"\n",
    "    input: col withs IDs_partXX\n",
    "    output: XX as int\n",
    "    Get numeric item in partXX from ID_partXX\n",
    "    \"\"\"\n",
    "    part_str = x.split('_')[1]\n",
    "    \n",
    "    if len(re.findall(r\"[\\.]\", part_str)) != 0: return int(part_str.split('.')[1])\n",
    "    elif len(re.findall(r\"t\", part_str)) != 0: return int(part_str.split('t')[1])\n",
    "    else: print(f\"Error. Couldnt find anything to split part to\")\n",
    "\n",
    "def get_ID(x):\n",
    "    \"\"\"\n",
    "    input: localID_partXX\n",
    "    output: localID\n",
    "    \"\"\"\n",
    "    return x.split('_')[0]\n",
    "\n",
    "def separate_parts(gdf, cols = ['']):\n",
    "    \"\"\"\n",
    "    If it is a geodf with ID_partXX then both parts are separated in different cols\n",
    "    This is necessary to be able to join gdfs\n",
    "    \"\"\"\n",
    "    print(f\"-------------- Checking for COLS to separate in {gdf.name} --------------\")\n",
    "    assert type(cols) == list\n",
    "    \n",
    "    c = 0\n",
    "    for col in cols:\n",
    "        if (len(re.findall(r\"_\", gdf[col].tolist()[0])) != 0) and col in gdf.columns.tolist():\n",
    "    \n",
    "            print(f\"{c+1}. {col}\\t\\t Dropped\")            \n",
    "            splited_col_name = re.split(r\"_\", gdf[col].tolist()[0])\n",
    "            part_title = re.findall(r\"\\D+\", splited_col_name[1])\n",
    "\n",
    "            gdf[col + f'_{part_title[0]}'] = gdf[col].apply(get_part).astype(dtype = 'int64')\n",
    "            gdf[col] = gdf[col].apply(get_ID)\n",
    "            c += 1\n",
    "        else: print(f\"No columns to separate\")\n",
    "            \n",
    "    print(f\"-- Finished task -----------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-144-2d4afbe6a891>, line 23)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-144-2d4afbe6a891>\"\u001b[0;36m, line \u001b[0;32m23\u001b[0m\n\u001b[0;31m    gdf['yearOfConstruction'] = gdf[LifeSpanCol].apply(get_year)\u001b[0m\n\u001b[0m      ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------ datetime operations\n",
    "\n",
    "def get_year(strng):\n",
    "    \"\"\"\n",
    "    Input:  string\n",
    "    Output: year as string\n",
    "    \n",
    "    Note_____________________________________________________________\n",
    "    Pandas requires years to be inside the bound of 1677 - 2262\n",
    "    To use pandas Timestamp it is need to defined custom Stamp Period\n",
    "    String operations seems easier in this case\n",
    "    \"\"\"\n",
    "    first_w = strng.split('T')[0]\n",
    "    return first_w.split('-')[0]\n",
    "\n",
    "def getYearOfConstruction(gdf, LifeSpanCol = 'beginLifespanVersion', drop_col = True):\n",
    "    \"\"\"\n",
    "    Cleaning Datetime\n",
    "    \"\"\"\n",
    "    print(f\"-- Getting YEAR OF CONSTRUCTION in {gdf.name} --------------------------\")\n",
    "    \n",
    "    if LifeSpanCol in gdf.columns.tolist(): \n",
    "    gdf['yearOfConstruction'] = gdf[LifeSpanCol].apply(get_year)\n",
    "    \n",
    "        if drop_col:\n",
    "            print(f\"Droping col {drop_col}: \\t{LifeSpanCol}\")\n",
    "            gdf.drop(LifeSpanCol, axis = 1, inplace = True)        \n",
    "\n",
    "        else: print(f\"Droping col {drop_col}: \\t{LifeSpanCol}\")\n",
    "    \n",
    "    print(f\"-- Finished task -----------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------ Droping duplicated columns\n",
    "\n",
    "def check_allTrue(gdf, col1, col2):\n",
    "    \"\"\"\n",
    "    Esta función se usa en ....\n",
    "    \"\"\"\n",
    "    print(f\"-- Checking if PAIRS are ALL TRUE {gdf.name} ---------------\")\n",
    "    \n",
    "    # hay columnas que son alturas y otras num de plantas. Con multiplicar x3 se arregla\n",
    "    if False not in gdf.apply(lambda x: (x[col1] == x[col2]) or (x[col1] == 3*x[col2]) or (3*x[col1] == x[col2]),\n",
    "                              axis = 1).value_counts().index.tolist():\n",
    "        \n",
    "        print(f\"All True --\\n-- Droping {col2}\")\n",
    "        gdf.drop([col2], axis = 1, inplace = True)\n",
    "    else:\n",
    "        print(f\"Pass \\tThere are inequalities between columns\")\n",
    "\n",
    "\n",
    "def checking_forIdenCols(gdf, drop_cols = True):\n",
    "    \"\"\"\n",
    "    Note_____________________________________________________________\n",
    "    Same unique elements are an indication that they give the same \n",
    "    (or nearly) the same information, therefore to simply ddbb\n",
    "    all columns that give the same info are purged\n",
    "    \"\"\"\n",
    "    print(f\"------------- Checking for SAME LEN COLS in {gdf.name} -----------------\")\n",
    "    \n",
    "    # 1 // creating vars for search\n",
    "    cols = [col for col in gdf.columns.tolist() if (col not in GEOMETRY_COLS)]\n",
    "    len_unique_cols = [len(gdf[col].value_counts().tolist()) for col in cols]\n",
    "    equal_cols, del_cols = [], []\n",
    "    \n",
    "    # 2 // creating pairs of columns that are suspect of giving the same information\n",
    "    for tup_len, tup_col in zip(list(combinations(len_unique_cols, 2)), list(combinations(cols, 2))):\n",
    "        if tup_len[0] == tup_len[1]:\n",
    "            equal_cols.append([tup_col[0], tup_col[1]])\n",
    "        else: pass\n",
    "\n",
    "    # 3 // if True, drop columns that are equal, evaluating if all rows are the same       \n",
    "    if drop_cols and len(equal_cols) != 0:        \n",
    "        for pair in equal_cols:\n",
    "            \n",
    "            if pair[1] not in del_cols:\n",
    "                gdf.drop(pair[1], axis = 1, inplace = True)\n",
    "                del_cols.append(pair.pop(1))\n",
    "            else: pass\n",
    "                \n",
    "        print(f\"1. Deleted   columns: \") # repr without new line\n",
    "        [print(f'\\t\\t\\t{i+1}. {col} \\v') for i, col in enumerate(del_cols)]; print('\\n')\n",
    "        \n",
    "        print(f\"2. Remaining columns: \") # repr without new line\n",
    "        [print(f'\\t\\t\\t{i+1}. {col} \\v') for i, col in enumerate(list(chain.from_iterable(equal_cols)))]\n",
    "        \n",
    "    # 4 // printing columns that remain after purging\n",
    "    elif len(equal_cols) == 0: print('List to return is empty')\n",
    "    else: \n",
    "        print(f\"Remaining columns: \\n\") # repr without new line\n",
    "        [print(f'\\t\\t\\t{i+1}. {col} \\v') for i, col in enumerate(list(chain.from_iterable(equal_cols)))]\n",
    "\n",
    "    print(f\"-- Finished task -----------------------------------------------------\\n\")\n",
    "    return list(chain.from_iterable(equal_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------ Unify ID columns if gml_id is dropped\n",
    "    \n",
    "def get_strPoint(x):\n",
    "    \"\"\"\n",
    "    Returns last part of Cadastral ID in gml_id inside shorten_localID\n",
    "    \"\"\"\n",
    "    return x.split('.')[-1]\n",
    "\n",
    "def shorten_localID(gdf, cols_to_shorten = ['gml_id']):\n",
    "    \"\"\"\n",
    "    If localId is dropped in favor of gml_id\n",
    "    Then, namespace part is purged of name\n",
    "    \"\"\"\n",
    "    print(f\"------- Checking for ID col to shorten in {gdf.name} -------------------\")\n",
    "    \n",
    "    shorted_localID = np.vectorize(get_strPoint)   \n",
    "    for col_ID in cols_to_shorten:\n",
    "        if col_ID in gdf.columns.tolist():\n",
    "            print(f'Shortening columns: {col_ID}')\n",
    "            gdf[col_ID] = shorted_localID(gdf[col_ID])\n",
    "            \n",
    "        else: print(f'Nothing to shorten')\n",
    "    \n",
    "    print(f\"-- Finished task -----------------------------------------------------\\n\")\n",
    "    \n",
    "# ------------------------------------------------------------ LAST STEP, unify columns names\n",
    "\n",
    "def rename_cols(gdf):\n",
    "    \"\"\"\n",
    "    If col not in dict, then pass.\n",
    "    This is used to unify all geojson\n",
    "    \"\"\"\n",
    "    print(f\"--------------- Renaming cols in {gdf.name} ----------------------------\")\n",
    "    \n",
    "    dict_cols_to_rename = RENAMING_OF_COLS # dict\n",
    "    cols_to_rename = [col for col in gdf.columns.tolist() if col in dict_cols_to_rename.keys()]\n",
    "    \n",
    "    gdf.rename(columns = dict_cols_to_rename, inplace = True) # before: after\n",
    "            \n",
    "    print(f\"1. Initial name: \") # repr without new line\n",
    "    [print(f'\\t\\t\\t{i+1}. {col} \\v') for i, col in enumerate(cols_to_rename)]\n",
    "\n",
    "    print(f\"2. Final name: \") # repr without new line\n",
    "    [print(f'\\t\\t\\t{i+1}. {dict_cols_to_rename[col]} \\v') for i, col in enumerate(cols_to_rename)]\n",
    "    \n",
    "    print(f\"-- Finished task -----------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rawData_infoCleaning(gdf, \n",
    "                         drop_cols = True, \n",
    "                         cols_to_separate = ['localId', 'gml_id'],\n",
    "                         datetime_col = 'beginLifespanVersion'):\n",
    "    \"\"\"\n",
    "    Pipeline towards clearer data\n",
    "    \"\"\"\n",
    "    print(f\"Initiating cleaning pipeline -----------------------------------------\\n\")\n",
    "    \n",
    "    # -- 1 -- SEARCHING FOR COLS WITHOUT DATA IN {gdf.name} -----------------------\n",
    "    droping_DupCols(gdf, drop_cols = drop_cols)\n",
    "    # -- 2 -- SEARCHING FOR UNIQUE COLS {gdf.name} --------------------------------\n",
    "    checking_forUniques(gdf)\n",
    "    # -- 3 -- SEARCHING FOR COLS TO SEPARATE {gdf.name} ---------------------------\n",
    "    separate_parts(gdf = gdf, cols = cols_to_separate)\n",
    "    # -- 4 -- SEARCHING FOR DUPLICATED INFO {gdf.name} ----------------------------\n",
    "    checking_forIdenCols(gdf, drop_cols = drop_cols)\n",
    "    # -- 5 -- REFORMATTING DATA IN {gdf.name} -------------------------------------\n",
    "    getYearOfConstruction(gdf, LifeSpanCol = datetime_col, drop_col = drop_cols)\n",
    "    shorten_localID(gdf)\n",
    "    # -- 6 -- RENAMING INFORMATION IN {gdf.name} ----------------------------------\n",
    "    rename_cols(gdf)\n",
    "    \n",
    "\n",
    "    print(f\"Closing cleaning pipeline --------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CAPAS DISPONIBLES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dada el volumen de datos, la inspección de éstos se realiza sobre una parte de éstos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "CATASTRO_PATH = '../data/raw/catastro'\n",
    "\n",
    "# Dentro de los datos displibles hay 4 capas en formato geojson\n",
    "\n",
    "#building_df = gpd.read_file(f\"{CATASTRO_PATH}/A.ES.SDGC.BU.28900.building.geojson\", rows = 25000)\n",
    "#buildingParts_df = gpd.read_file(f\"{CATASTRO_PATH}/A.ES.SDGC.BU.28900.buildingpart.geojson\", rows = 25000) # pt 1\n",
    "otherConstruction_df = gpd.read_file(f\"{CATASTRO_PATH}/A.ES.SDGC.BU.28900.otherconstruction.geojson\", rows = 25000)\n",
    "cadastralParcel = gpd.read_file(f\"{CATASTRO_PATH}/A.ES.SDGC.CP.28900.cadastralparcel.geojson\", rows = 25000)\n",
    "cadastralZoning = gpd.read_file(f\"{CATASTRO_PATH}/A.ES.SDGC.CP.28900.cadastralzoning.geojson\", rows = 25000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checkeo de uso de memoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Other Construction Layer total memory usage: \t\t774.16 \t\tKbytes\n",
      "Cadastral Parcel Layer total memory usage: \t\t2200.128 \tKbytes\n",
      "Cadastral Zoning Layer total memory usage: \t\t1269.136 \tKbytes\n"
     ]
    }
   ],
   "source": [
    "#print(f\"Building Layer total memory usage: \\t\\t\\t{building_df.memory_usage(index=True).sum()/1000} \\tKbytes\")\n",
    "#print(f\"Building Parts Layer total memory usage: \\t\\t{buildingParts_df.memory_usage(index=True).sum()/1000} \\tKbytes\")\n",
    "print(f\"Other Construction Layer total memory usage: \\t\\t{otherConstruction_df.memory_usage(index=True).sum()/1000} \\t\\tKbytes\")\n",
    "print(f\"Cadastral Parcel Layer total memory usage: \\t\\t{cadastralParcel.memory_usage(index=True).sum()/1000} \\tKbytes\")\n",
    "print(f\"Cadastral Zoning Layer total memory usage: \\t\\t{cadastralZoning.memory_usage(index=True).sum()/1000} \\tKbytes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "## NAMES OF GEO\n",
    "# IN OBJECT MAKE IT SO THAT filename == NAME\n",
    "#building_df.name = 'BU_ALL'\n",
    "#buildingParts_df.name = 'BU_PARTS'\n",
    "otherConstruction_df.name = 'BU_OTHER'\n",
    "cadastralParcel.name = 'CAD_PARCEL'\n",
    "cadastralZoning.name = 'CAD_ZONING'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Building Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En qGIS esta capa representa la parte edificada de los solares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(building_df.info())\n",
    "display(building_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "building_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GETTING RID OF USELESS COLUMNS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DROP NULL COLUMNS\n",
    "# There are a couple of columns that do not offer any information\n",
    "\n",
    "building_nullCols = ['numberOfFloorsAboveGround', 'endLifespanVersion']\n",
    "building_linkCols = ['documentLink', 'format', 'informationSystem']\n",
    "building_measureCols = ['horizontalGeometryEstimatedAccuracy', 'value_uom', 'sourceStatus',\n",
    "                        'horizontalGeometryEstimatedAccuracy_uom', 'horizontalGeometryReference', \n",
    "                        'officialAreaReference']\n",
    "\n",
    "building_df.drop(building_nullCols,    axis=1, inplace = True)\n",
    "building_df.drop(building_linkCols,    axis=1, inplace = True)\n",
    "building_df.drop(building_measureCols, axis=1, inplace = True)\n",
    "\n",
    "# horizontalGeometryEstimatedAccuracy is always 0.1m accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CORRECTING GROSS FLOOR AREA\n",
    "# officialAreaReference - value - value_uom are columns that refer to the same information\n",
    "\n",
    "building_df.rename(columns={\"value\": \"grossFloorArea\"}, inplace = True)\n",
    "# building_df.drop(['officialAreaReference'], axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SIMPLIFYING DATE COLUMNS\n",
    "# changes between them migt be because of difference between registration or CFO.\n",
    "# end column has no sense in the context of this project\n",
    "\n",
    "building_dateCols = ['beginLifespanVersion', 'beginning', 'end']\n",
    "\n",
    "# ARE beginning and end the same\n",
    "\n",
    "building_df['Equal_beg_end'] = building_df.apply(lambda x: x['beginning'] == x['end'], axis = 1)\n",
    "building_df['Equal_beg_end'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the rest of DATES columns.\n",
    "In the [bibliography](#http://www.catastro.minhap.es/webinspire/documentos/Conjuntos%20de%20datos.pdf) it says:\n",
    ">- **beginLifespanVersion**: Fecha desde cuándo se ha dado de alta en la base de datos\n",
    "catastral. \n",
    ">- **dateOfConstruction**: estructura que define la fecha de construcción. Está compuesta por dos atributos: bu-c**ore2d:beginning y bu-core2d:end**; los valores son las fechas de construcción de cada unidad constructiva, si hay más de una en el campo **“beginning” se incluye la más antigua y en el campo “end” la más moderna** Siempre se referencian al 1 de enero . \n",
    "\n",
    "**______**\n",
    "Para este proyecto, sólo nos interesa la columna beginning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dont know what this means.. could be buildings that are demolished or abandoned\n",
    "# Lets look to the first row reference = 000207800VK56E\n",
    "# Sede Electronica del Catastro says that this building has been built in 2004, the *end* year\n",
    "# Most plausible cause is that the builing is abandoned, in construction etc, is a phase of reconstruction\n",
    "\n",
    "# conditionOfConstruction should be different\n",
    "# Lets see that\n",
    "\n",
    "c_functional, c_declined, c_ruin = 0, 0, 0\n",
    "\n",
    "for ref in building_df[building_df['Equal_beg_end'] == False]['reference'].tolist() :\n",
    "    if building_df[building_df['reference'] == ref]['conditionOfConstruction'].tolist()[0] == 'functional':\n",
    "        c_functional += 1\n",
    "    elif building_df[building_df['reference'] == ref]['conditionOfConstruction'].tolist()[0] == 'declined':\n",
    "        c_declined += 1\n",
    "    elif building_df[building_df['reference'] == ref]['conditionOfConstruction'].tolist()[0] == 'ruin':\n",
    "        c_ruin += 1\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "print(f\"FOR BUILDINGS WITH THE DIFFERENT BEGINNING AND END DATES. CONDITION OF CONSTRUCTION\")\n",
    "print(f\"Functional : \\t{c_functional}\")\n",
    "print(f\"Declined : \\t{c_declined}\")\n",
    "print(f\"Ruins : \\t{c_ruin}\")\n",
    "\n",
    "# There should be another category\n",
    "# Buildings that may have another new cadastral reference for unknown reasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LETS SEE CONDITION OF CONSTRUCTION COLUMN\n",
    "building_df['conditionOfConstruction'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LETS ADD another category for demolished buildings, that reflects beginning != end\n",
    "# por tanto, los edificios en donde se ha construido suelen son edificios funcionales\n",
    "# \n",
    "# Como se ha dicho más arriba, sólo nos interesa la columna BEGINNING para efectos de este proyecto\n",
    "\n",
    "building_df.drop(['Equal_beg_end', 'end', 'beginLifespanVersion'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "\n",
    "building_df['dateOfConstruction'] = building_df['beginning'].apply(lambda x: \n",
    "                                    dt.datetime.strptime(x,'%Y-%m-%dT%H:%M:%S'))\n",
    "\n",
    "# Out of bounds nanosecond timestamp: 1640-01-01 00:00:00\n",
    "# Pandas required YEARS to be inside de bound of 1670 - 2560,\n",
    "# Because of the nature of data, datetime methods cannot be used for this case\n",
    "\n",
    "def get_yearofConstruction(strng):\n",
    "    \"\"\"\n",
    "    Input:  string\n",
    "    Output: year as string\n",
    "    \"\"\"\n",
    "    first_w = strng.split('T')[0]\n",
    "    # Not using datetime from pandas, not valid for this case\n",
    "    return first_w.split('-')[0]\n",
    "\n",
    "building_df['yearOfConstruction'] = building_df['beginning'].apply(get_yearofConstruction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "building_df.drop(['beginning', 'dateOfConstruction'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**____________________________________________________________________________________________________________**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THERE ARE COLUMNS THAT MAY DUPLICATE INFORMATION\n",
    "# To join with the rest of data, parcels, buildingparts... share an ID\n",
    "# Which col is the ID ??\n",
    "\n",
    "cols_id = ['gml_id', 'reference', 'localId', 'namespace']\n",
    "\n",
    "# Reference == localID ?? \n",
    "# See if there are unique values, or repeteated values (this info has to be contrasted with the rest of geojson)\n",
    "\n",
    "building_df[cols_id].describe()\n",
    "\n",
    "# All elements are unique (as expected)\n",
    "# SHOULD COINCIDE WITH PARCELS\n",
    "# gml_id for later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Are reference and localID the same? \n",
    "building_df.apply(lambda x: x['reference'] == x['localId'], axis = 1).value_counts() # TRUE\n",
    "# What is reference Geometry ?\n",
    "building_df['referenceGeometry'].value_counts() # All true --> Dropping\n",
    "\n",
    "# Dropping reference and namespace\n",
    "building_df.drop(['reference', 'namespace', 'referenceGeometry'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "building_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**____________________________________________________________________________________________________________**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**____________________________________________________________________________________________________________**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Building Parts Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'geopandas.geodataframe.GeoDataFrame'>\n",
      "RangeIndex: 25000 entries, 0 to 24999\n",
      "Data columns (total 7 columns):\n",
      " #   Column                     Non-Null Count  Dtype   \n",
      "---  ------                     --------------  -----   \n",
      " 0   gml_id                     25000 non-null  object  \n",
      " 1   beginLifespanVersion       25000 non-null  object  \n",
      " 2   localId                    25000 non-null  object  \n",
      " 3   numberOfFloorsAboveGround  25000 non-null  int64   \n",
      " 4   heightBelowGround          25000 non-null  int64   \n",
      " 5   numberOfFloorsBelowGround  25000 non-null  int64   \n",
      " 6   geometry                   25000 non-null  geometry\n",
      "dtypes: geometry(1), int64(3), object(3)\n",
      "memory usage: 1.3+ MB\n",
      "None\n",
      "\n",
      "Shape of BU_PARTS: \t\t\t     (25000, 7)\n"
     ]
    }
   ],
   "source": [
    "print(f\"{buildingParts_df.info()}\\n\")\n",
    "print(f\"Shape of {buildingParts_df.name}: \\t\\t\\t     {buildingParts_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initiating cleaning pipeline -----------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Current Layers in BU_PARTS ------------------------\n",
      "------------------------------------------------------------------------\n",
      "1. gml_id:\t\t\t\t\t25000\tUnique items\n",
      "2. beginLifespanVersion:\t\t\t974\tUnique items\n",
      "3. localId:\t\t\t\t\t25000\tUnique items\n",
      "4. numberOfFloorsAboveGround:\t\t\t21\tUnique items\n",
      "5. heightBelowGround:\t\t\t\t11\tUnique items\n",
      "6. numberOfFloorsBelowGround:\t\t\t11\tUnique items\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "-------------- Droping DUPLICATED COLUMNS in BU_PARTS ------------------\n",
      "-- Finished task -----------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Current Layers in BU_PARTS ------------------------\n",
      "------------------------------------------------------------------------\n",
      "1. gml_id:\t\t\t\t\t25000\tUnique items\n",
      "2. beginLifespanVersion:\t\t\t974\tUnique items\n",
      "3. localId:\t\t\t\t\t25000\tUnique items\n",
      "4. numberOfFloorsAboveGround:\t\t\t21\tUnique items\n",
      "5. heightBelowGround:\t\t\t\t11\tUnique items\n",
      "6. numberOfFloorsBelowGround:\t\t\t11\tUnique items\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "-------------- Checking for COLS to separate in BU_PARTS --------------\n",
      "1. localId\t\t Dropped\n",
      "2. gml_id\t\t Dropped\n",
      "-- Finished task -----------------------------------------------------\n",
      "\n",
      "------------- Checking for SAME LEN COLS in BU_PARTS -----------------\n",
      "1. Deleted   columns: \n",
      "\t\t\t1. localId \u000b",
      "\n",
      "\t\t\t2. numberOfFloorsBelowGround \u000b",
      "\n",
      "\t\t\t3. gml_id_part \u000b",
      "\n",
      "\n",
      "\n",
      "2. Remaining columns: \n",
      "\t\t\t1. gml_id \u000b",
      "\n",
      "\t\t\t2. heightBelowGround \u000b",
      "\n",
      "\t\t\t3. localId_part \u000b",
      "\n",
      "-- Finished task -----------------------------------------------------\n",
      "\n",
      "-- Getting YEAR OF CONSTRUCTION in BU_PARTS --------------------------\n",
      "Droping col True: \tbeginLifespanVersion\n",
      "-- Finished task -----------------------------------------------------\n",
      "\n",
      "------- Checking for ID col to shorten in BU_PARTS -------------------\n",
      "Shortening columns: gml_id\n",
      "-- Finished task -----------------------------------------------------\n",
      "\n",
      "--------------- Renaming cols in BU_PARTS ----------------------------\n",
      "1. Initial name: \n",
      "\t\t\t1. gml_id \u000b",
      "\n",
      "\t\t\t2. numberOfFloorsAboveGround \u000b",
      "\n",
      "\t\t\t3. heightBelowGround \u000b",
      "\n",
      "\t\t\t4. localId_part \u000b",
      "\n",
      "2. Final name: \n",
      "\t\t\t1. ID \u000b",
      "\n",
      "\t\t\t2. nFloors_AG \u000b",
      "\n",
      "\t\t\t3. height_BG \u000b",
      "\n",
      "\t\t\t4. ID_part \u000b",
      "\n",
      "-- Finished task -----------------------------------------------------\n",
      "\n",
      "Closing cleaning pipeline --------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rawData_infoCleaning(buildingParts_df, \n",
    "                     drop_cols = True, \n",
    "                     cols_to_separate = ['localId', 'gml_id'], \n",
    "                     datetime_col = 'beginLifespanVersion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>nFloors_AG</th>\n",
       "      <th>height_BG</th>\n",
       "      <th>geometry</th>\n",
       "      <th>ID_part</th>\n",
       "      <th>yearOfConstruction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000200100VK48E</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>POLYGON ((441657.574 4487050.292, 441658.164 4...</td>\n",
       "      <td>1</td>\n",
       "      <td>2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000200500VK56E</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>POLYGON ((451584.920 4467181.410, 451586.250 4...</td>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000200500VK56E</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>POLYGON ((451612.580 4467215.370, 451618.650 4...</td>\n",
       "      <td>2</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               ID  nFloors_AG  height_BG  \\\n",
       "0  000200100VK48E           1          0   \n",
       "1  000200500VK56E           1          0   \n",
       "2  000200500VK56E           1          0   \n",
       "\n",
       "                                            geometry  ID_part  \\\n",
       "0  POLYGON ((441657.574 4487050.292, 441658.164 4...        1   \n",
       "1  POLYGON ((451584.920 4467181.410, 451586.250 4...        1   \n",
       "2  POLYGON ((451612.580 4467215.370, 451618.650 4...        2   \n",
       "\n",
       "  yearOfConstruction  \n",
       "0               2004  \n",
       "1               2013  \n",
       "2               2013  "
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buildingParts_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**________________________**\n",
    "\n",
    "**________________________**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Other Construction Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All data corresponds to open AIR POOLS\n",
    "# I don't need this dataset to begin with\n",
    "# BUT lets cleaned it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'geopandas.geodataframe.GeoDataFrame'>\n",
      "RangeIndex: 13822 entries, 0 to 13821\n",
      "Data columns (total 7 columns):\n",
      " #   Column                   Non-Null Count  Dtype   \n",
      "---  ------                   --------------  -----   \n",
      " 0   gml_id                   13822 non-null  object  \n",
      " 1   beginLifespanVersion     13822 non-null  object  \n",
      " 2   conditionOfConstruction  0 non-null      object  \n",
      " 3   localId                  13822 non-null  object  \n",
      " 4   namespace                13822 non-null  object  \n",
      " 5   constructionNature       13822 non-null  object  \n",
      " 6   geometry                 13822 non-null  geometry\n",
      "dtypes: geometry(1), object(6)\n",
      "memory usage: 756.0+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(13822, 7)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(otherConstruction_df.info())\n",
    "display(otherConstruction_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initiating cleaning pipeline -----------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Current Layers in BU_OTHER ------------------------\n",
      "------------------------------------------------------------------------\n",
      "1. gml_id:\t\t\t\t\t13822\tUnique items\n",
      "2. beginLifespanVersion:\t\t\t2191\tUnique items\n",
      "3. conditionOfConstruction:\t\t\t0\tALL NULLS\n",
      "4. localId:\t\t\t\t\t13822\tUnique items\n",
      "5. namespace:\t\t\t\t\t1\tUnique items\n",
      "6. constructionNature:\t\t\t\t1\tUnique items\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "-------------- Droping DUPLICATED COLUMNS in BU_OTHER ------------------\n",
      "1. conditionOfConstruction\u000b",
      "\n",
      "2. namespace\u000b",
      "\n",
      "3. constructionNature\u000b",
      "\n",
      "-- Finished task -----------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Current Layers in BU_OTHER ------------------------\n",
      "------------------------------------------------------------------------\n",
      "1. gml_id:\t\t\t\t\t13822\tUnique items\n",
      "2. beginLifespanVersion:\t\t\t2191\tUnique items\n",
      "3. localId:\t\t\t\t\t13822\tUnique items\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "-------------- Checking for COLS to separate in BU_OTHER --------------\n",
      "1. localId\t\t Dropped\n",
      "2. gml_id\t\t Dropped\n",
      "-- Finished task -----------------------------------------------------\n",
      "\n",
      "------------- Checking for SAME LEN COLS in BU_OTHER -----------------\n",
      "1. Deleted   columns: \n",
      "\t\t\t1. localId \u000b",
      "\n",
      "\t\t\t2. gml_id_PI. \u000b",
      "\n",
      "\n",
      "\n",
      "2. Remaining columns: \n",
      "\t\t\t1. gml_id \u000b",
      "\n",
      "\t\t\t2. localId_PI. \u000b",
      "\n",
      "-- Finished task -----------------------------------------------------\n",
      "\n",
      "-- Getting YEAR OF CONSTRUCTION in BU_OTHER --------------------------\n",
      "Droping col True: \tbeginLifespanVersion\n",
      "-- Finished task -----------------------------------------------------\n",
      "\n",
      "------- Checking for ID col to shorten in BU_OTHER -------------------\n",
      "Shortening columns: gml_id\n",
      "-- Finished task -----------------------------------------------------\n",
      "\n",
      "--------------- Renaming cols in BU_OTHER ----------------------------\n",
      "1. Initial name: \n",
      "\t\t\t1. gml_id \u000b",
      "\n",
      "2. Final name: \n",
      "\t\t\t1. ID \u000b",
      "\n",
      "-- Finished task -----------------------------------------------------\n",
      "\n",
      "Closing cleaning pipeline --------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rawData_infoCleaning(otherConstruction_df, \n",
    "                     drop_cols = True, \n",
    "                     cols_to_separate = ['localId', 'gml_id'], \n",
    "                     datetime_col = 'beginLifespanVersion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>geometry</th>\n",
       "      <th>localId_PI.</th>\n",
       "      <th>yearOfConstruction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0006601VK3800E</td>\n",
       "      <td>POLYGON ((429964.360 4480456.150, 429961.960 4...</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0007201VK3800E</td>\n",
       "      <td>POLYGON ((429883.850 4480596.541, 429888.120 4...</td>\n",
       "      <td>2</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0007202VK3800E</td>\n",
       "      <td>POLYGON ((429967.989 4480563.520, 429968.469 4...</td>\n",
       "      <td>3</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               ID                                           geometry  \\\n",
       "0  0006601VK3800E  POLYGON ((429964.360 4480456.150, 429961.960 4...   \n",
       "1  0007201VK3800E  POLYGON ((429883.850 4480596.541, 429888.120 4...   \n",
       "2  0007202VK3800E  POLYGON ((429967.989 4480563.520, 429968.469 4...   \n",
       "\n",
       "   localId_PI. yearOfConstruction  \n",
       "0            1               2017  \n",
       "1            2               2003  \n",
       "2            3               2006  "
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "otherConstruction_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**________________________**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Cadastral Parcel Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'geopandas.geodataframe.GeoDataFrame'>\n",
      "RangeIndex: 25000 entries, 0 to 24999\n",
      "Data columns (total 11 columns):\n",
      " #   Column                      Non-Null Count  Dtype   \n",
      "---  ------                      --------------  -----   \n",
      " 0   gml_id                      25000 non-null  object  \n",
      " 1   areaValue                   25000 non-null  int64   \n",
      " 2   areaValue_uom               25000 non-null  object  \n",
      " 3   beginLifespanVersion        25000 non-null  object  \n",
      " 4   endLifespanVersion          0 non-null      object  \n",
      " 5   localId                     25000 non-null  object  \n",
      " 6   namespace                   25000 non-null  object  \n",
      " 7   label                       25000 non-null  object  \n",
      " 8   nationalCadastralReference  25000 non-null  object  \n",
      " 9   pos                         25000 non-null  object  \n",
      " 10  geometry                    25000 non-null  geometry\n",
      "dtypes: geometry(1), int64(1), object(9)\n",
      "memory usage: 2.1+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(25000, 11)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(cadastralParcel.info())\n",
    "display(cadastralParcel.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initiating cleaning pipeline -----------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Current Layers in CAD_PARCEL ------------------------\n",
      "------------------------------------------------------------------------\n",
      "1. gml_id:\t\t\t\t\t25000\tUnique items\n",
      "2. areaValue:\t\t\t\t\t5910\tUnique items\n",
      "3. areaValue_uom:\t\t\t\t1\tUnique items\n",
      "4. beginLifespanVersion:\t\t\t1446\tUnique items\n",
      "5. endLifespanVersion:\t\t\t0\tALL NULLS\n",
      "6. localId:\t\t\t\t\t25000\tUnique items\n",
      "7. namespace:\t\t\t\t\t1\tUnique items\n",
      "8. label:\t\t\t\t\t768\tUnique items\n",
      "9. nationalCadastralReference:\t\t\t25000\tUnique items\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "-------------- Droping DUPLICATED COLUMNS in CAD_PARCEL ------------------\n",
      "1. areaValue_uom\u000b",
      "\n",
      "2. endLifespanVersion\u000b",
      "\n",
      "3. namespace\u000b",
      "\n",
      "-- Finished task -----------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Current Layers in CAD_PARCEL ------------------------\n",
      "------------------------------------------------------------------------\n",
      "1. gml_id:\t\t\t\t\t25000\tUnique items\n",
      "2. areaValue:\t\t\t\t\t5910\tUnique items\n",
      "3. beginLifespanVersion:\t\t\t1446\tUnique items\n",
      "4. localId:\t\t\t\t\t25000\tUnique items\n",
      "5. label:\t\t\t\t\t768\tUnique items\n",
      "6. nationalCadastralReference:\t\t\t25000\tUnique items\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "-------------- Checking for COLS to separate in CAD_PARCEL --------------\n",
      "No columns to separate\n",
      "No columns to separate\n",
      "-- Finished task -----------------------------------------------------\n",
      "\n",
      "------------- Checking for SAME LEN COLS in CAD_PARCEL -----------------\n",
      "1. Deleted   columns: \n",
      "\t\t\t1. localId \u000b",
      "\n",
      "\t\t\t2. nationalCadastralReference \u000b",
      "\n",
      "\n",
      "\n",
      "2. Remaining columns: \n",
      "\t\t\t1. gml_id \u000b",
      "\n",
      "\t\t\t2. gml_id \u000b",
      "\n",
      "\t\t\t3. localId \u000b",
      "\n",
      "\t\t\t4. nationalCadastralReference \u000b",
      "\n",
      "-- Finished task -----------------------------------------------------\n",
      "\n",
      "-- Getting YEAR OF CONSTRUCTION in CAD_PARCEL --------------------------\n",
      "Droping col True: \tbeginLifespanVersion\n",
      "-- Finished task -----------------------------------------------------\n",
      "\n",
      "------- Checking for ID col to shorten in CAD_PARCEL -------------------\n",
      "Shortening columns: gml_id\n",
      "-- Finished task -----------------------------------------------------\n",
      "\n",
      "--------------- Renaming cols in CAD_PARCEL ----------------------------\n",
      "1. Initial name: \n",
      "\t\t\t1. gml_id \u000b",
      "\n",
      "\t\t\t2. areaValue \u000b",
      "\n",
      "2. Final name: \n",
      "\t\t\t1. ID \u000b",
      "\n",
      "\t\t\t2. area_m2p \u000b",
      "\n",
      "-- Finished task -----------------------------------------------------\n",
      "\n",
      "Closing cleaning pipeline --------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rawData_infoCleaning(cadastralParcel, \n",
    "                     drop_cols = True, \n",
    "                     cols_to_separate = ['localId', 'gml_id'], \n",
    "                     datetime_col = 'beginLifespanVersion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>area_m2p</th>\n",
       "      <th>label</th>\n",
       "      <th>pos</th>\n",
       "      <th>geometry</th>\n",
       "      <th>yearOfConstruction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000200500VK56E</td>\n",
       "      <td>1268</td>\n",
       "      <td>005</td>\n",
       "      <td>451607.03 4467199.27</td>\n",
       "      <td>MULTIPOLYGON (((451599.360 4467174.940, 451584...</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000205600VK56E</td>\n",
       "      <td>297</td>\n",
       "      <td>056</td>\n",
       "      <td>451592.44 4467170.83</td>\n",
       "      <td>MULTIPOLYGON (((451593.000 4467163.250, 451579...</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000205700VK56E</td>\n",
       "      <td>155</td>\n",
       "      <td>057</td>\n",
       "      <td>451587.93 4467161.77</td>\n",
       "      <td>MULTIPOLYGON (((451590.040 4467156.910, 451576...</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000205800VK56E</td>\n",
       "      <td>174</td>\n",
       "      <td>058</td>\n",
       "      <td>451584.62 4467155.04</td>\n",
       "      <td>MULTIPOLYGON (((451586.650 4467149.650, 451573...</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               ID  area_m2p label                   pos  \\\n",
       "0  000200500VK56E      1268   005  451607.03 4467199.27   \n",
       "1  000205600VK56E       297   056  451592.44 4467170.83   \n",
       "2  000205700VK56E       155   057  451587.93 4467161.77   \n",
       "3  000205800VK56E       174   058  451584.62 4467155.04   \n",
       "\n",
       "                                            geometry yearOfConstruction  \n",
       "0  MULTIPOLYGON (((451599.360 4467174.940, 451584...               2013  \n",
       "1  MULTIPOLYGON (((451593.000 4467163.250, 451579...               2013  \n",
       "2  MULTIPOLYGON (((451590.040 4467156.910, 451576...               2013  \n",
       "3  MULTIPOLYGON (((451586.650 4467149.650, 451573...               2013  "
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cadastralParcel.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**________________________**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Cadastral Zoning Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'geopandas.geodataframe.GeoDataFrame'>\n",
      "RangeIndex: 12202 entries, 0 to 12201\n",
      "Data columns (total 13 columns):\n",
      " #   Column                           Non-Null Count  Dtype   \n",
      "---  ------                           --------------  -----   \n",
      " 0   gml_id                           12202 non-null  object  \n",
      " 1   beginLifespanVersion             12202 non-null  object  \n",
      " 2   endLifespanVersion               0 non-null      object  \n",
      " 3   estimatedAccuracy                12202 non-null  float64 \n",
      " 4   estimatedAccuracy_uom            12202 non-null  object  \n",
      " 5   localId                          12202 non-null  object  \n",
      " 6   namespace                        12202 non-null  object  \n",
      " 7   label                            12202 non-null  object  \n",
      " 8   LocalisedCharacterString         12202 non-null  object  \n",
      " 9   nationalCadastalZoningReference  12202 non-null  object  \n",
      " 10  originalMapScaleDenominator      12202 non-null  int64   \n",
      " 11  pos                              12202 non-null  object  \n",
      " 12  geometry                         12202 non-null  geometry\n",
      "dtypes: float64(1), geometry(1), int64(1), object(10)\n",
      "memory usage: 1.2+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(12202, 13)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(cadastralZoning.info())\n",
    "display(cadastralZoning.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5    12111\n",
       "1.0       91\n",
       "Name: estimatedAccuracy, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "500     12111\n",
       "5000       91\n",
       "Name: originalMapScaleDenominator, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "MANZANA      12111\n",
       "POLIGONO        91\n",
       "Name: LocalisedCharacterString, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Nota_______________________________________________________________________ \n",
      "\n",
      "estimatedAccuracy == originalMapScaleDenominator == LocalisedCharacterString\n",
      "\n",
      "              0.5 == 500                     500 == MANZANA                 \n",
      "\n",
      "              1.0 == 5000                   5000 == POLIGONO                \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## son iguales ---> SI, son las mismas\n",
    "display(cadastralZoning['estimatedAccuracy'].value_counts())\n",
    "display(cadastralZoning['originalMapScaleDenominator'].value_counts())\n",
    "display(cadastralZoning['LocalisedCharacterString'].value_counts()) # son iguales ??\n",
    "\n",
    "cadastralZoning.apply(lambda x : x['estimatedAccuracy'] == 0.5 and \\\n",
    "                                 x['LocalisedCharacterString'] == 'MANZANA ' and \\\n",
    "                                 x['originalMapScaleDenominator'] == 500,\n",
    "                      axis = 1).value_counts() # All true\n",
    "print(\"\"\"\n",
    "Nota_______________________________________________________________________ \\n\n",
    "estimatedAccuracy == originalMapScaleDenominator == LocalisedCharacterString\\n\n",
    "              0.5 == 500                     500 == MANZANA                 \\n\n",
    "              1.0 == 5000                   5000 == POLIGONO                \\n\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initiating cleaning pipeline -----------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Current Layers in CAD_ZONING ------------------------\n",
      "------------------------------------------------------------------------\n",
      "1. gml_id:\t\t\t\t\t12202\tUnique items\n",
      "2. beginLifespanVersion:\t\t\t2381\tUnique items\n",
      "3. endLifespanVersion:\t\t\t0\tALL NULLS\n",
      "4. estimatedAccuracy:\t\t\t\t2\tUnique items\n",
      "5. estimatedAccuracy_uom:\t\t\t1\tUnique items\n",
      "6. localId:\t\t\t\t\t12202\tUnique items\n",
      "7. namespace:\t\t\t\t\t1\tUnique items\n",
      "8. label:\t\t\t\t\t11507\tUnique items\n",
      "9. LocalisedCharacterString:\t\t\t2\tUnique items\n",
      "10. nationalCadastalZoningReference:\t\t12202\tUnique items\n",
      "11. originalMapScaleDenominator:\t\t\t2\tUnique items\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "-------------- Droping DUPLICATED COLUMNS in CAD_ZONING ------------------\n",
      "1. endLifespanVersion\u000b",
      "\n",
      "2. estimatedAccuracy_uom\u000b",
      "\n",
      "3. namespace\u000b",
      "\n",
      "-- Finished task -----------------------------------------------------\n",
      "\n",
      "\n",
      "-------------------- Current Layers in CAD_ZONING ------------------------\n",
      "------------------------------------------------------------------------\n",
      "1. gml_id:\t\t\t\t\t12202\tUnique items\n",
      "2. beginLifespanVersion:\t\t\t2381\tUnique items\n",
      "3. estimatedAccuracy:\t\t\t\t2\tUnique items\n",
      "4. localId:\t\t\t\t\t12202\tUnique items\n",
      "5. label:\t\t\t\t\t11507\tUnique items\n",
      "6. LocalisedCharacterString:\t\t\t2\tUnique items\n",
      "7. nationalCadastalZoningReference:\t\t12202\tUnique items\n",
      "8. originalMapScaleDenominator:\t\t\t2\tUnique items\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "-------------- Checking for COLS to separate in CAD_ZONING --------------\n",
      "No columns to separate\n",
      "No columns to separate\n",
      "-- Finished task -----------------------------------------------------\n",
      "\n",
      "------------- Checking for SAME LEN COLS in CAD_ZONING -----------------\n",
      "1. Deleted   columns: \n",
      "\t\t\t1. localId \u000b",
      "\n",
      "\t\t\t2. nationalCadastalZoningReference \u000b",
      "\n",
      "\t\t\t3. LocalisedCharacterString \u000b",
      "\n",
      "\t\t\t4. originalMapScaleDenominator \u000b",
      "\n",
      "\n",
      "\n",
      "2. Remaining columns: \n",
      "\t\t\t1. gml_id \u000b",
      "\n",
      "\t\t\t2. gml_id \u000b",
      "\n",
      "\t\t\t3. estimatedAccuracy \u000b",
      "\n",
      "\t\t\t4. estimatedAccuracy \u000b",
      "\n",
      "\t\t\t5. localId \u000b",
      "\n",
      "\t\t\t6. nationalCadastalZoningReference \u000b",
      "\n",
      "\t\t\t7. LocalisedCharacterString \u000b",
      "\n",
      "\t\t\t8. originalMapScaleDenominator \u000b",
      "\n",
      "-- Finished task -----------------------------------------------------\n",
      "\n",
      "-- Getting YEAR OF CONSTRUCTION in CAD_ZONING --------------------------\n",
      "Droping col True: \tbeginLifespanVersion\n",
      "-- Finished task -----------------------------------------------------\n",
      "\n",
      "------- Checking for ID col to shorten in CAD_ZONING -------------------\n",
      "Shortening columns: gml_id\n",
      "-- Finished task -----------------------------------------------------\n",
      "\n",
      "--------------- Renaming cols in CAD_ZONING ----------------------------\n",
      "1. Initial name: \n",
      "\t\t\t1. gml_id \u000b",
      "\n",
      "2. Final name: \n",
      "\t\t\t1. ID \u000b",
      "\n",
      "-- Finished task -----------------------------------------------------\n",
      "\n",
      "Closing cleaning pipeline --------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rawData_infoCleaning(cadastralZoning, \n",
    "                     drop_cols = True, \n",
    "                     cols_to_separate = ['localId', 'gml_id'], \n",
    "                     datetime_col = 'beginLifespanVersion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>estimatedAccuracy</th>\n",
       "      <th>label</th>\n",
       "      <th>pos</th>\n",
       "      <th>geometry</th>\n",
       "      <th>yearOfConstruction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28900A000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>000</td>\n",
       "      <td>440302.42 4492704.6</td>\n",
       "      <td>MULTIPOLYGON (((440301.968 4492704.637, 440302...</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28900A001</td>\n",
       "      <td>1.0</td>\n",
       "      <td>001</td>\n",
       "      <td>444909.27 4497953.5</td>\n",
       "      <td>MULTIPOLYGON (((444555.092 4499363.444, 444568...</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28900A002</td>\n",
       "      <td>1.0</td>\n",
       "      <td>002</td>\n",
       "      <td>446474.92 4496527.94</td>\n",
       "      <td>MULTIPOLYGON (((445948.540 4496495.370, 445945...</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28900A003</td>\n",
       "      <td>1.0</td>\n",
       "      <td>003</td>\n",
       "      <td>447749.11 4494280.98</td>\n",
       "      <td>MULTIPOLYGON (((449091.096 4493635.359, 449089...</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28900A004</td>\n",
       "      <td>1.0</td>\n",
       "      <td>004</td>\n",
       "      <td>447065.76 4493887.71</td>\n",
       "      <td>MULTIPOLYGON (((445797.560 4495048.620, 445790...</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID  estimatedAccuracy label                   pos  \\\n",
       "0  28900A000                1.0   000   440302.42 4492704.6   \n",
       "1  28900A001                1.0   001   444909.27 4497953.5   \n",
       "2  28900A002                1.0   002  446474.92 4496527.94   \n",
       "3  28900A003                1.0   003  447749.11 4494280.98   \n",
       "4  28900A004                1.0   004  447065.76 4493887.71   \n",
       "\n",
       "                                            geometry yearOfConstruction  \n",
       "0  MULTIPOLYGON (((440301.968 4492704.637, 440302...               2019  \n",
       "1  MULTIPOLYGON (((444555.092 4499363.444, 444568...               2019  \n",
       "2  MULTIPOLYGON (((445948.540 4496495.370, 445945...               2013  \n",
       "3  MULTIPOLYGON (((449091.096 4493635.359, 449089...               2014  \n",
       "4  MULTIPOLYGON (((445797.560 4495048.620, 445790...               2013  "
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cadastralZoning.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_______________**\n",
    "\n",
    "**_______________**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CHECKING MEMORY USAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Parts Layer total memory usage: \t\t1200.128 \tKbytes\n",
      "Other Construction Layer total memory usage: \t\t442.432 \tKbytes\n",
      "Cadastral Parcel Layer total memory usage: \t\t1200.128 \tKbytes\n",
      "Cadastral Zoning Layer total memory usage: \t\t585.824 \t\tKbytes\n"
     ]
    }
   ],
   "source": [
    "#print(f\"Building Layer total memory usage: \\t\\t\\t{building_df.memory_usage(index=True).sum()/1000} \\tKbytes\")\n",
    "print(f\"Building Parts Layer total memory usage: \\t\\t{buildingParts_df.memory_usage(index=True).sum()/1000} \\tKbytes\")\n",
    "print(f\"Other Construction Layer total memory usage: \\t\\t{otherConstruction_df.memory_usage(index=True).sum()/1000} \\tKbytes\")\n",
    "\n",
    "print(f\"Cadastral Parcel Layer total memory usage: \\t\\t{cadastralParcel.memory_usage(index=True).sum()/1000} \\tKbytes\")\n",
    "print(f\"Cadastral Zoning Layer total memory usage: \\t\\t{cadastralZoning.memory_usage(index=True).sum()/1000} \\t\\tKbytes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- INITIALLY---\n",
    "\n",
    "    Building Layer total memory usage: \t\t\t     4825.128 \tKbytes\n",
    "    Building Parts Layer total memory usage: \t\t 2625.128 \tKbytes\n",
    "    Other Construction Layer total memory usage: \t 774.16 \tKbytes\n",
    "    Cadastral Parcel Layer total memory usage: \t\t 2200.128 \tKbytes\n",
    "    Cadastral Zoning Layer total memory usage: \t\t 1269.136 \tKbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Parts Layer memory optimization: \t\t45.72 \t%\n",
      "Other Construction Layer memory optimization: \t\t57.15 \t%\n",
      "Cadastral Parcel Layer memory optimization: \t\t54.55 \t%\n",
      "Cadastral Zoning Layer memory optimization: \t\t46.16 \t%\n"
     ]
    }
   ],
   "source": [
    "## CHANGE\n",
    "\n",
    "#print(f\"Building Layer memory optimization: \\t\\t\\t{np.round(building_df.memory_usage(index=True).sum()/(10*4825.128), 2)} \\t%\")\n",
    "print(f\"Building Parts Layer memory optimization: \\t\\t{np.round(buildingParts_df.memory_usage(index=True).sum()/(10*2625.128), 2)} \\t%\")\n",
    "print(f\"Other Construction Layer memory optimization: \\t\\t{np.round(otherConstruction_df.memory_usage(index=True).sum()/(10*774.16), 2)} \\t%\")\n",
    "\n",
    "print(f\"Cadastral Parcel Layer memory optimization: \\t\\t{np.round(cadastralParcel.memory_usage(index=True).sum()/(10*2200.128), 2)} \\t%\")\n",
    "print(f\"Cadastral Zoning Layer memory optimization: \\t\\t{np.round(cadastralZoning.memory_usage(index=True).sum()/(10*1269.136), 2)} \\t%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_______________**\n",
    "\n",
    "**_______________**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CHECKINF WHICH COL IS BETTER TO CONNECT TABLES IN DDBB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BU_id = np.array(building_df['gml_id']); display(BU_id); display(len(BU_id))\n",
    "BP_id = np.array(buildingParts_df['gml_id']); display(BP_id); display(len(BP_id))\n",
    "BO_id = np.array(otherConstruction_df['gml_id']); display(BO_id); display(len(BO_id))\n",
    "CP_id = np.array(cadastralParcel['gml_id']); display(CP_id); display(len(CP_id))\n",
    "CZ_id = np.array(cadastralZoning['gml_id']); display(CZ_id); display(len(CZ_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "geoesp_env",
   "language": "python",
   "name": "geoesp_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
